{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data as torchdata\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.utils import compute_sample_weight\n",
    "from sklearn import metrics\n",
    "\n",
    "# usual imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# loading dataset\n",
    "from data_loader import TIHMDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the path with the path of your dataset\n",
    "DPATH = '../Dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TIHMDataset(\n",
    "    root=DPATH, train=True, normalise='global', n_days=7\n",
    "    )\n",
    "#train data set\n",
    "\n",
    "test_dataset = TIHMDataset(\n",
    "    root=DPATH, train=False, normalise='global', n_days=7\n",
    "    )\n",
    "#test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target names are:\n",
      "['Blood pressure', 'Agitation', 'Body water', 'Pulse', 'Weight', 'Body temperature']\n"
     ]
    }
   ],
   "source": [
    "print(f\"The target names are:\\n{train_dataset.target_names}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset can be passed to a dataloader: (we will apply some pre-processing and define these again later)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define the problem. We want to use the input data to predict there was agitation on a given day using the past 7 days worth of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgitationDataset(torchdata.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.data, self.target = [], []\n",
    "        \n",
    "        for x, y in dataset:\n",
    "            self.data.append(torch.tensor(x).float())#iterate through the provided dataset convert the input features into PyTorch tensors\n",
    "            self.target.append(np.int64(y[-1, 1]>=1)) # the last of the days and agitation\n",
    "        \n",
    "        # also define the sample weight\n",
    "        self.sw = compute_sample_weight(class_weight='balanced', y=self.target)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.target[index], self.sw[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_agitation_dataset = AgitationDataset(train_dataset)\n",
    "test_agitation_dataset = AgitationDataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the values in the PyTorch library\n",
    "train_dl = torchdata.DataLoader(\n",
    "    dataset=train_agitation_dataset, batch_size=1000, shuffle=True,\n",
    "    )\n",
    "\n",
    "test_dl = torchdata.DataLoader(\n",
    "    dataset=test_agitation_dataset, batch_size=1000, shuffle=False,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an LSTM model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple LSTM\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, sequence_length, hidden_size):\n",
    "#input_dim, sequence_length, hidden_size???\n",
    "        \n",
    "        super().__init__()\n",
    "#super()is used to copy the functions from another classes (i.e. nn.Module)\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, input_dim),\n",
    "            nn.BatchNorm1d(num_features=sequence_length),#normalizes the outputs \n",
    "            nn.ReLU(),#introduces non-linearity\n",
    "            )\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_dim, hidden_size, batch_first=True,\n",
    "            )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 2)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1, :] # get the value from the last of the sequence\n",
    "        x = self.layer2(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimiser, train_loader, n_epochs):\n",
    "    \n",
    "    training_loss = []\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'#check to gpu\n",
    "    model.to(device)\n",
    "\n",
    "    def one_batch(x, y, sw):\n",
    "        x, y, sw = x.to(device), y.to(device), sw.to(device)\n",
    "        criterion.zero_grad()#resets the gradients\n",
    "        output = model(x) # gets the output after passing the input data through the model.\n",
    "        loss = criterion(output, y,)\n",
    "        loss = (loss * sw / sw.sum()).sum() #computes the sum of the computed loss \n",
    "        loss.mean().backward() #computes the average loss \n",
    "        optimiser.step()\n",
    "        return loss\n",
    "\n",
    "    def one_epoch(train_loader):\n",
    "        epoch_loss = []\n",
    "        for batch in train_loader:\n",
    "            loss = one_batch(*batch)\n",
    "            epoch_loss.append(loss.item())\n",
    "        return epoch_loss\n",
    "\n",
    "    for epoch in tqdm.tqdm(range(n_epochs), desc='Training'):  #visual progress bar \n",
    "        epoch_loss = one_epoch(train_loader)\n",
    "        training_loss.extend(epoch_loss)\n",
    "\n",
    "    model.to('cpu')\n",
    "\n",
    "    return training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x = next(iter(train_dl))[0]\n",
    "lstm = LSTMModel(batch_x.shape[2], batch_x.shape[1], 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|██████████████████▉              | 23/40 [00:03<00:02,  6.41it/s]"
     ]
    }
   ],
   "source": [
    "training_loss = train(\n",
    "    model=lstm, \n",
    "    criterion=nn.CrossEntropyLoss(reduction='none'), \n",
    "    optimiser=torch.optim.Adam(lstm.parameters(), lr=0.001),\n",
    "    train_loader=train_dl,\n",
    "    n_epochs=40,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_loader):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "\n",
    "    predictions = []\n",
    "    targets = []\n",
    "\n",
    "    for x, y, sw in test_loader:\n",
    "        x, y, sw = x.to(device), y.to(device), sw.to(device)\n",
    "        outputs = model(x)\n",
    "        predictions.append(F.softmax(outputs, dim=1))\n",
    "        targets.append(y)\n",
    "    \n",
    "    return torch.cat(predictions).to('cpu'), torch.cat(targets).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, targets = predict(lstm, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = metrics.recall_score(targets, predictions.max(dim=1).indices)\n",
    "print(f\"The recall was {recall*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfm = metrics.confusion_matrix(targets, predictions.max(dim=1).indices)\n",
    "print(f\"The confusion matrix is:\\n{cfm}\")\n",
    "# TN   FP\n",
    "# FN   TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Compute confusion matrix\n",
    "cfm = metrics.confusion_matrix(targets, predictions.max(dim=1).indices)\n",
    "\n",
    "# Normalize the confusion matrix by dividing each value by the sum of the row (true labels)\n",
    "cfm_percentage = cfm.astype('float') / cfm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "# Create a ConfusionMatrixDisplay object\n",
    "disp = ConfusionMatrixDisplay(cfm_percentage, display_labels=['No Agitation', 'Agitation'])\n",
    "\n",
    "# Plot confusion matrix with \"Predicted\" and \"True\" labels\n",
    "fig, ax = plt.subplots(figsize=(6, 6))  # Adjust size as needed\n",
    "disp.plot(cmap=plt.cm.Blues, ax=ax, values_format=\".2f\")  # Display two decimal places\n",
    "\n",
    "# Customize axis labels\n",
    "ax.set_xlabel('Predicted Labels')\n",
    "ax.set_ylabel('True Labels')\n",
    "\n",
    "# Add title\n",
    "plt.title('LSTM Confusion Matrix with Percentages')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity = cfm[1,1]/cfm[1,:].sum()\n",
    "print(f\"The sensitivity is: {sensitivity*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specificity = cfm[0,0]/cfm[0,:].sum()\n",
    "print(f\"The specificity is: {specificity*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = cfm.trace() / cfm.sum()  # trace() gives the sum of diagonal elements (true positives + true negatives)\n",
    "print(f\"The accuracy is: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = cfm[1,1] / cfm[:,1].sum()  # True Positives / (True Positives + False Positives)\n",
    "print(f\"The precision is: {precision*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(model, test_loader):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "\n",
    "    predictions = []\n",
    "    targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y, _ in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = model(x)\n",
    "            predictions.append(F.softmax(outputs, dim=1)[:, 1].cpu().numpy())  # Probabilities for the positive class\n",
    "            targets.append(y.cpu().numpy())\n",
    "    \n",
    "    return np.concatenate(predictions), np.concatenate(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs, true_labels = predict_proba(lstm, test_dl)\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Compute ROC curve values\n",
    "fpr, tpr, _ = roc_curve(true_labels, probs)\n",
    "\n",
    "# Calculate AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(f\"The AUC is: {roc_auc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Obtain model predictions\n",
    "probs, true_labels = predict_proba(lstm, test_dl)\n",
    "\n",
    "# Get predicted labels\n",
    "pred_labels = probs >= 0.5  # Convert probabilities to binary predictions\n",
    "\n",
    "# Compute precision and recall\n",
    "precision = precision_score(true_labels, pred_labels)\n",
    "recall = recall_score(true_labels, pred_labels)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(true_labels, pred_labels)\n",
    "print(f\"The F1 score is: {f1*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BLSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, sequence_length, hidden_size, num_layers=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Layer 1: Linear and BatchNorm followed by ReLU\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, input_dim),\n",
    "            nn.BatchNorm1d(num_features=sequence_length),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # Bidirectional LSTM layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_dim, hidden_size, num_layers=num_layers, batch_first=True, bidirectional=True\n",
    "        )\n",
    "        \n",
    "        # Layer 2: Linear layer for output, considering bidirectional\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, 2)  # Multiply by 2 due to bidirectionality\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass through Layer 1\n",
    "        x = self.layer1(x)\n",
    "        \n",
    "        # Pass through LSTM (outputs both hidden states for forward and backward directions)\n",
    "        x, _ = self.lstm(x)\n",
    "        \n",
    "        # Take the last hidden state from both directions\n",
    "        x = torch.cat((x[:, -1, :self.lstm.hidden_size], x[:, 0, self.lstm.hidden_size:]), dim=1)\n",
    "        \n",
    "        # Pass through Layer 2 for classification\n",
    "        x = self.layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x = next(iter(train_dl))[0]\n",
    "blstm = BLSTMModel(batch_x.shape[2], batch_x.shape[1], 200)\n",
    "\n",
    "training_loss = train(\n",
    "    model=blstm, \n",
    "    criterion=nn.CrossEntropyLoss(reduction='none'), \n",
    "    optimiser=torch.optim.Adam(blstm.parameters(), lr=0.001),\n",
    "    train_loader=train_dl,\n",
    "    n_epochs=40,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, targets = predict(blstm, test_dl)\n",
    "\n",
    "b_recall = metrics.recall_score(targets, predictions.max(dim=1).indices)\n",
    "print(f\"The recall was {b_recall*100:.2f}%\")\n",
    "\n",
    "bcfm = metrics.confusion_matrix(targets, predictions.max(dim=1).indices)\n",
    "print(f\"The confusion matrix is:\\n{bcfm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcfm = metrics.confusion_matrix(targets, predictions.max(dim=1).indices)\n",
    "\n",
    "# Normalize the confusion matrix by dividing each value by the sum of the row (true labels)\n",
    "bcfm_percentage = bcfm.astype('float') / bcfm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "# Create a ConfusionMatrixDisplay object\n",
    "disp = ConfusionMatrixDisplay(bcfm_percentage, display_labels=['No Agitation', 'Agitation'])\n",
    "\n",
    "# Plot confusion matrix with \"Predicted\" and \"True\" labels\n",
    "fig, ax = plt.subplots(figsize=(6, 6))  # Adjust size as needed\n",
    "disp.plot(cmap=plt.cm.Blues, ax=ax, values_format=\".2f\")  # Display two decimal places\n",
    "\n",
    "# Customize axis labels\n",
    "ax.set_xlabel('Predicted Labels')\n",
    "ax.set_ylabel('True Labels')\n",
    "\n",
    "# Add title\n",
    "plt.title('B-LSTM Confusion Matrix with Percentages')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_sensitivity = bcfm[1,1]/bcfm[1,:].sum()\n",
    "print(f\"The sensitivity is: {b_sensitivity*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_specificity = bcfm[0,0]/bcfm[0,:].sum()\n",
    "print(f\"The specificity is: {b_specificity*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_accuracy = bcfm.trace() / bcfm.sum()  # trace() gives the sum of diagonal elements (true positives + true negatives)\n",
    "print(f\"The accuracy is: {b_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_precision = bcfm[1,1] / bcfm[:,1].sum()  # True Positives / (True Positives + False Positives)\n",
    "print(f\"The precision is: {b_precision*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs, true_labels = predict_proba(blstm, test_dl)\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Compute ROC curve values\n",
    "fpr, tpr, _ = roc_curve(true_labels, probs)\n",
    "\n",
    "# Calculate AUC\n",
    "b_roc_auc = auc(fpr, tpr)\n",
    "print(f\"The AUC is: {b_roc_auc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs, true_labels = predict_proba(blstm, test_dl)\n",
    "\n",
    "# Get predicted labels\n",
    "pred_labels = probs >= 0.5  # Convert probabilities to binary predictions\n",
    "\n",
    "\n",
    "\n",
    "# Calculate F1 score\n",
    "b_f1 = f1_score(true_labels, pred_labels)\n",
    "print(f\"The F1 score is: {b_f1*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define metrics names and values for two models\n",
    "metrics_names = ['Precision', 'Recall', 'Sensitivity', 'Specificity', 'Accuracy', 'F1 Score', 'AUC']\n",
    "model_a_values = [precision, recall, sensitivity, specificity, accuracy, f1, roc_auc]\n",
    "model_b_values = [b_precision, b_recall, b_sensitivity, b_specificity, b_accuracy, b_f1, b_roc_auc]\n",
    "\n",
    "# Define number of bars and their positions\n",
    "bar_width = 0.35  # Width of the bars\n",
    "index = np.arange(len(metrics_names))  # The label locations\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot bars for model A\n",
    "plt.bar(index, model_a_values, bar_width, label='LSTM', color='skyblue')\n",
    "\n",
    "# Plot bars for model B, shifted by bar_width\n",
    "plt.bar(index + bar_width, model_b_values, bar_width, label='BLSTM', color='lightgreen')\n",
    "\n",
    "# Add labels and formatting\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Percentage')\n",
    "plt.title('Comparison of Performance Metrics between Models')\n",
    "plt.xticks(index + bar_width / 2, metrics_names, rotation=45, ha='right')  # Align x labels\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "8ffa9458eb812bc86d8ec9c6172a4488b6504c6d9033306e2462dfb6e563f266"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
